{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ad Detection Pipeline Using Fine-Tuned Sentence Transformer and Support Vector Machine (Also Before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Batches: 100%|██████████| 369/369 [00:09<00:00, 40.63it/s]\n",
      "Batches: 100%|██████████| 93/93 [00:02<00:00, 38.32it/s]\n",
      "Batches: 100%|██████████| 369/369 [00:08<00:00, 41.11it/s]\n",
      "Batches: 100%|██████████| 93/93 [00:02<00:00, 41.45it/s]\n",
      "Batches: 100%|██████████| 369/369 [00:08<00:00, 41.35it/s]\n",
      "Batches: 100%|██████████| 93/93 [00:02<00:00, 41.15it/s]\n",
      "Batches: 100%|██████████| 369/369 [00:08<00:00, 41.10it/s]\n",
      "Batches: 100%|██████████| 93/93 [00:02<00:00, 41.03it/s]\n",
      "Batches: 100%|██████████| 369/369 [00:09<00:00, 40.64it/s]\n",
      "Batches: 100%|██████████| 93/93 [00:02<00:00, 40.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1 Score (for ad detection, label=1) on Combined Training Set: [0.58476027 0.59096665 0.5841714  0.58031088 0.57700651]\n",
      "Mean Cross-validation F1 Score: 0.5834431437150649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 461/461 [00:11<00:00, 38.69it/s]\n",
      "Batches: 100%|██████████| 461/461 [00:11<00:00, 40.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined Training Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.69      0.74      9616\n",
      "           1       0.54      0.69      0.61      5128\n",
      "\n",
      "    accuracy                           0.69     14744\n",
      "   macro avg       0.67      0.69      0.68     14744\n",
      "weighted avg       0.72      0.69      0.70     14744\n",
      "\n",
      "Confusion Matrix (Combined Training):\n",
      "[[6639 2977]\n",
      " [1590 3538]]\n",
      "F1 Score for ads (label 1): 0.6077471442068195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 82/82 [00:02<00:00, 40.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.69      0.73      1687\n",
      "           1       0.52      0.63      0.57       913\n",
      "\n",
      "    accuracy                           0.67      2600\n",
      "   macro avg       0.65      0.66      0.65      2600\n",
      "weighted avg       0.69      0.67      0.67      2600\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[1168  519]\n",
      " [ 341  572]]\n",
      "F1 Score for ads (label 1): 0.5708582834331337\n",
      "Detection Accuracy for ads (label 1): 0.6265060240963856\n",
      "False Negative Rate for ads (label 1): 0.37349397590361444\n",
      "False Positive Rate for ads (label 1): 0.3076467101363367\n",
      "F1-score for detecting ads: 0.5708582834331337\n",
      "Detection Accuracy for non-ads (label 0): 0.6923532898636633\n",
      "False Negative Rate for non-ads (label 0): 0.3076467101363367\n",
      "False Positive Rate for non-ads (label 0): 0.37349397590361444\n",
      "F1-score for non-detecting ads (label 0): 0.7309136420525657\n",
      "\n",
      "Submission file saved to: /root/Ad-Detection/Submission/svm-baseline.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Custom transformer to wrap a Sentence Transformer model\n",
    "class SentenceTransformerVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        self.model_name = model_name\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Generate sentence embeddings\n",
    "        embeddings = self.model.encode(X, batch_size=32, show_progress_bar=True)\n",
    "        return embeddings\n",
    "\n",
    "def load_dataset(responses_file, labels_file):\n",
    "    \"\"\"\n",
    "    Load dataset by reading responses and labels from JSONL files and merging them.\n",
    "    \"\"\"\n",
    "    # Load responses into a dictionary mapping id -> response text\n",
    "    responses = {}\n",
    "    with open(responses_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            responses[data[\"id\"]] = data[\"response\"]\n",
    "    \n",
    "    # Load labels and merge with responses\n",
    "    ids, texts, labels = [], [], []\n",
    "    with open(labels_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            instance_id = data[\"id\"]\n",
    "            if instance_id in responses:\n",
    "                ids.append(instance_id)\n",
    "                texts.append(responses[instance_id])\n",
    "                labels.append(data[\"label\"])\n",
    "    \n",
    "    return ids, texts, labels\n",
    "\n",
    "# File paths (update these paths as needed)\n",
    "train_responses_file = '/root/Ad-Detection/Dataset/responses-train.jsonl'\n",
    "train_labels_file = '/root/Ad-Detection/Dataset/responses-train-labels.jsonl'\n",
    "val_responses_file   = '/root/Ad-Detection/Dataset/responses-validation.jsonl'\n",
    "val_labels_file      = '/root/Ad-Detection/Dataset/responses-validation-labels.jsonl'\n",
    "test_responses_file  = '/root/Ad-Detection/Dataset/responses-test.jsonl'\n",
    "test_labels_file     = '/root/Ad-Detection/Dataset/responses-test-labels.jsonl'\n",
    "\n",
    "# Load train and validation datasets separately\n",
    "train_ids, train_texts, train_labels = load_dataset(train_responses_file, train_labels_file)\n",
    "val_ids, val_texts, val_labels = load_dataset(val_responses_file, val_labels_file)\n",
    "\n",
    "# Combine train and validation sets into one training set\n",
    "combined_ids = train_ids + val_ids\n",
    "combined_texts = train_texts + val_texts\n",
    "combined_labels = train_labels + val_labels\n",
    "\n",
    "# Load test dataset\n",
    "test_ids, test_texts, test_labels = load_dataset(test_responses_file, test_labels_file)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Experiment: Logistic Regression with Sentence Transformer Embeddings for Advertisement Detection\n",
    "# Classifier: Logistic Regression (predicts label 1 as advertisement)\n",
    "# Feature Extraction: Sentence Transformer to generate embeddings\n",
    "# Goal: Evaluate performance specifically for detecting advertisements (label 1)\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# Build the pipeline: Sentence Transformer vectorizer + Logistic Regression\n",
    "pipeline = make_pipeline(\n",
    "    SentenceTransformerVectorizer(model_name='all-MiniLM-L6-v2'),\n",
    "    LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Cross-Validation on Combined Training Set\n",
    "# -------------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Use scoring 'f1' which, for binary classification, computes the F1 score for the positive class (label 1)\n",
    "cv_scores = cross_val_score(pipeline, combined_texts, combined_labels, cv=cv, scoring='f1')\n",
    "print(\"Cross-validation F1 Score (for ad detection, label=1) on Combined Training Set:\", cv_scores)\n",
    "print(\"Mean Cross-validation F1 Score:\", np.mean(cv_scores))\n",
    "\n",
    "# -------------------------\n",
    "# Train the Model on the Full Combined Training Set\n",
    "# -------------------------\n",
    "pipeline.fit(combined_texts, combined_labels)\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Combined Training Set\n",
    "# -------------------------\n",
    "train_preds = pipeline.predict(combined_texts)\n",
    "train_report_dict = classification_report(combined_labels, train_preds, output_dict=True)\n",
    "train_cm = confusion_matrix(combined_labels, train_preds)\n",
    "# Save training evaluation to CSV\n",
    "df_train_report = pd.DataFrame(train_report_dict).transpose()\n",
    "df_train_report.to_csv('/root/Ad-Detection/csv-result/svm/train_classification_report.csv', index=True)\n",
    "\n",
    "df_train_cm = pd.DataFrame(train_cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "df_train_cm.to_csv('/root/Ad-Detection/csv-result/svm/train_confusion_matrix.csv', index=True)\n",
    "\n",
    "print(\"\\nCombined Training Set Evaluation:\")\n",
    "print(classification_report(combined_labels, train_preds))\n",
    "print(\"Confusion Matrix (Combined Training):\")\n",
    "print(confusion_matrix(combined_labels, train_preds))\n",
    "# Calculate F1 Score for label 1 explicitly:\n",
    "print(\"F1 Score for ads (label 1):\", f1_score(combined_labels, train_preds, pos_label=1))\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Test Set\n",
    "# -------------------------\n",
    "test_preds = pipeline.predict(test_texts)\n",
    "test_report_dict = classification_report(test_labels, test_preds, output_dict=True)\n",
    "test_cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "# Save test evaluation to CSV\n",
    "df_test_report = pd.DataFrame(test_report_dict).transpose()\n",
    "df_test_report.to_csv('/root/Ad-Detection/csv-result/svm/test_classification_report.csv', index=True)\n",
    "\n",
    "df_test_cm = pd.DataFrame(test_cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "df_test_cm.to_csv('/root/Ad-Detection/csv-result/svm/test_confusion_matrix.csv', index=True)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(classification_report(test_labels, test_preds))\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "print(\"Confusion Matrix (Test):\")\n",
    "print(cm)\n",
    "print(\"F1 Score for ads (label 1):\", f1_score(test_labels, test_preds, pos_label=1))\n",
    "\n",
    "# Calculate additional metrics for label 1 based on the confusion matrix\n",
    "TN, FP, FN, TP = cm[0,0], cm[0,1], cm[1,0], cm[1,1]\n",
    "detection_accuracy = TP / (TP + FN) if (TP + FN) > 0 else 0  # Recall for ads\n",
    "false_negative_rate = FN / (TP + FN) if (TP + FN) > 0 else 0\n",
    "false_positive_rate = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "\n",
    "print(\"Detection Accuracy for ads (label 1):\", detection_accuracy)\n",
    "print(\"False Negative Rate for ads (label 1):\", false_negative_rate)\n",
    "print(\"False Positive Rate for ads (label 1):\", false_positive_rate)\n",
    "\n",
    "# Additional snippet to calculate and print the F1 score for detecting ads (label 1)\n",
    "f1_ads = f1_score(test_labels, test_preds, pos_label=1)\n",
    "print(\"F1-score for detecting ads:\", f1_ads)\n",
    "\n",
    "# Calculate additional metrics for label 0 (non-ads) by treating label 0 as the positive class\n",
    "detection_accuracy_non_ads = TN / (TN + FP) if (TN + FP) > 0 else 0  # Recall for non-ads\n",
    "false_negative_rate_non_ads = FP / (TN + FP) if (TN + FP) > 0 else 0\n",
    "false_positive_rate_non_ads = FN / (FN + TP) if (FN + TP) > 0 else 0\n",
    "\n",
    "print(\"Detection Accuracy for non-ads (label 0):\", detection_accuracy_non_ads)\n",
    "print(\"False Negative Rate for non-ads (label 0):\", false_negative_rate_non_ads)\n",
    "print(\"False Positive Rate for non-ads (label 0):\", false_positive_rate_non_ads)\n",
    "f1_non_ads = f1_score(test_labels, test_preds, pos_label=0)\n",
    "print(\"F1-score for non-detecting ads (label 0):\", f1_non_ads)\n",
    "\n",
    "# -------------------------\n",
    "# Submission File Generation\n",
    "# -------------------------\n",
    "submission_file = '/root/Ad-Detection/Submission/svm-baseline.jsonl'\n",
    "with open(submission_file, 'w', encoding='utf-8') as f_out:\n",
    "    for instance_id, pred in zip(test_ids, test_preds):\n",
    "        result = {\n",
    "            \"id\": instance_id,\n",
    "            \"label\": int(pred),  # ensuring it's an integer (0 or 1)\n",
    "            \"tag\": \"myGroupMyMethod\"\n",
    "        }\n",
    "        f_out.write(json.dumps(result) + \"\\n\")\n",
    "        \n",
    "print(f\"\\nSubmission file saved to: {submission_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 461/461 [00:11<00:00, 41.73it/s]\n",
      "Batches: 100%|██████████| 82/82 [00:01<00:00, 42.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1687\n",
      "           1       0.97      0.96      0.97       913\n",
      "\n",
      "    accuracy                           0.98      2600\n",
      "   macro avg       0.98      0.97      0.97      2600\n",
      "weighted avg       0.98      0.98      0.98      2600\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1662   25]\n",
      " [  37  876]]\n",
      "F1 Score for ads (label 1): 0.9658213891951488\n",
      "Detection Accuracy for ads (label 1): 0.9594742606790799\n",
      "False Negative Rate for ads (label 1): 0.040525739320920046\n",
      "False Positive Rate for ads (label 1): 0.014819205690574985\n",
      "\n",
      "Submission file saved to: /root/Ad-Detection/Submission/baseline-SVM.jsonl\n",
      "Evaluation metrics saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "# ---------------------------------------\n",
    "# Data Loading Function\n",
    "# ---------------------------------------\n",
    "def load_dataset(responses_file, labels_file):\n",
    "    \"\"\"\n",
    "    Load dataset by reading responses and labels from JSONL files and merging them.\n",
    "    \"\"\"\n",
    "    responses = {}\n",
    "    with open(responses_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            responses[data[\"id\"]] = data[\"response\"]\n",
    "    \n",
    "    ids, texts, labels = [], [], []\n",
    "    with open(labels_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            instance_id = data[\"id\"]\n",
    "            if instance_id in responses:\n",
    "                ids.append(instance_id)\n",
    "                texts.append(responses[instance_id])\n",
    "                labels.append(data[\"label\"])\n",
    "    \n",
    "    return ids, texts, labels\n",
    "\n",
    "# ---------------------------------------\n",
    "# File Paths (Update these paths as needed)\n",
    "# ---------------------------------------\n",
    "train_responses_file = '/root/Ad-Detection/Dataset/responses-train.jsonl'\n",
    "train_labels_file    = '/root/Ad-Detection/Dataset/responses-train-labels.jsonl'\n",
    "val_responses_file   = '/root/Ad-Detection/Dataset/responses-validation.jsonl'\n",
    "val_labels_file      = '/root/Ad-Detection/Dataset/responses-validation-labels.jsonl'\n",
    "test_responses_file  = '/root/Ad-Detection/Dataset/responses-test.jsonl'\n",
    "test_labels_file     = '/root/Ad-Detection/Dataset/responses-test-labels.jsonl'\n",
    "\n",
    "# ---------------------------------------\n",
    "# Load Datasets\n",
    "# ---------------------------------------\n",
    "train_ids, train_texts, train_labels = load_dataset(train_responses_file, train_labels_file)\n",
    "val_ids, val_texts, val_labels = load_dataset(val_responses_file, val_labels_file)\n",
    "\n",
    "# Combine training and validation data\n",
    "combined_ids = train_ids + val_ids\n",
    "combined_texts = train_texts + val_texts\n",
    "combined_labels = train_labels + val_labels\n",
    "\n",
    "# Load test dataset\n",
    "test_ids, test_texts, test_labels = load_dataset(test_responses_file, test_labels_file)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Load the Fine-Tuned Sentence Transformer Model\n",
    "# ---------------------------------------\n",
    "# Load your fine-tuned model from the saved path.\n",
    "fine_tuned_model_path = '/root/Ad-Detection/Fine-Tune-model/fine_tuned_all-MiniLM-L6-v2'\n",
    "model = SentenceTransformer(fine_tuned_model_path)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Extract Embeddings\n",
    "# ---------------------------------------\n",
    "# Generate embeddings for the training (combined) and test texts.\n",
    "train_embeddings = model.encode(combined_texts, batch_size=32, show_progress_bar=True)\n",
    "test_embeddings  = model.encode(test_texts, batch_size=32, show_progress_bar=True)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Train an SVM Classifier\n",
    "# ---------------------------------------\n",
    "# We use an SVM with a linear kernel and balanced class weights.\n",
    "svm_clf = SVC(kernel='linear', class_weight='balanced', probability=True, random_state=42)\n",
    "svm_clf.fit(train_embeddings, combined_labels)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Evaluate the Classifier on the Test Set\n",
    "# ---------------------------------------\n",
    "test_preds = svm_clf.predict(test_embeddings)\n",
    "print(\"Test Set Evaluation:\")\n",
    "print(classification_report(test_labels, test_preds))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_labels, test_preds))\n",
    "print(\"F1 Score for ads (label 1):\", f1_score(test_labels, test_preds, pos_label=1))\n",
    "\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "TN, FP, FN, TP = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]\n",
    "detection_accuracy = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "false_negative_rate = FN / (TP + FN) if (TP + FN) > 0 else 0\n",
    "false_positive_rate = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "\n",
    "print(\"Detection Accuracy for ads (label 1):\", detection_accuracy)\n",
    "print(\"False Negative Rate for ads (label 1):\", false_negative_rate)\n",
    "print(\"False Positive Rate for ads (label 1):\", false_positive_rate)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Generate Submission File (Optional)\n",
    "# ---------------------------------------\n",
    "submission_file = '/root/Ad-Detection/Submission/baseline-SVM.jsonl'\n",
    "with open(submission_file, 'w', encoding='utf-8') as f_out:\n",
    "    for instance_id, pred in zip(test_ids, test_preds):\n",
    "        result = {\n",
    "            \"id\": instance_id,\n",
    "            \"label\": int(pred),\n",
    "            \"tag\": \"myGroupMyMethod\"\n",
    "        }\n",
    "        f_out.write(json.dumps(result) + \"\\n\")\n",
    "print(f\"\\nSubmission file saved to: {submission_file}\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# Save Evaluation Metrics to CSV Files\n",
    "# ---------------------------------------\n",
    "# Create a DataFrame from the classification report\n",
    "test_report_dict = classification_report(test_labels, test_preds, output_dict=True)\n",
    "df_test_report = pd.DataFrame(test_report_dict).transpose()\n",
    "df_test_report.to_csv('/root/Ad-Detection/csv-result/svm/fune-tuned-Results/test_classification_report.csv', index=True)\n",
    "\n",
    "# Create a DataFrame for the confusion matrix\n",
    "df_cm = pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "df_cm.to_csv('/root/Ad-Detection/csv-result/svm/fune-tuned-Results/test_confusion_matrix.csv', index=True)\n",
    "\n",
    "print(\"Evaluation metrics saved to CSV files.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
