{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1 Macro Scores on Training Set: [0.42259069 0.41886949 0.42067236 0.41584924 0.41454145]\n",
      "Mean Cross-Validation F1 Macro Score: 0.41850464756880407\n",
      "\n",
      "Training Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80      7541\n",
      "           1       0.98      0.07      0.13      3946\n",
      "\n",
      "    accuracy                           0.68     11487\n",
      "   macro avg       0.82      0.54      0.47     11487\n",
      "weighted avg       0.78      0.68      0.57     11487\n",
      "\n",
      "Confusion Matrix (Training):\n",
      "[[7534    7]\n",
      " [3663  283]]\n",
      "\n",
      "Validation Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79      2075\n",
      "           1       0.95      0.05      0.09      1182\n",
      "\n",
      "    accuracy                           0.65      3257\n",
      "   macro avg       0.80      0.52      0.44      3257\n",
      "weighted avg       0.76      0.65      0.53      3257\n",
      "\n",
      "Confusion Matrix (Validation):\n",
      "[[2072    3]\n",
      " [1124   58]]\n",
      "\n",
      "Test Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79      1687\n",
      "           1       1.00      0.02      0.04       913\n",
      "\n",
      "    accuracy                           0.66      2600\n",
      "   macro avg       0.83      0.51      0.41      2600\n",
      "weighted avg       0.78      0.66      0.53      2600\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[1687    0]\n",
      " [ 895   18]]\n",
      "\n",
      "Submission file saved to: /Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/nbc_baseline.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "def load_dataset(responses_file, labels_file):\n",
    "    \"\"\"\n",
    "    Load dataset by reading responses and labels from JSONL files and merging them.\n",
    "    \"\"\"\n",
    "    # Load responses into a dictionary mapping id -> response text\n",
    "    responses = {}\n",
    "    with open(responses_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            # Here you can combine 'query' and 'response' if needed.\n",
    "            responses[data[\"id\"]] = data[\"response\"]\n",
    "    \n",
    "    # Load labels and merge with responses\n",
    "    ids, texts, labels = [], [], []\n",
    "    with open(labels_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            instance_id = data[\"id\"]\n",
    "            if instance_id in responses:\n",
    "                ids.append(instance_id)\n",
    "                texts.append(responses[instance_id])\n",
    "                labels.append(data[\"label\"])\n",
    "    \n",
    "    return ids, texts, labels\n",
    "\n",
    "# File paths (update these paths as needed)\n",
    "train_responses_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-train.jsonl'\n",
    "train_labels_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-train-labels.jsonl'\n",
    "val_responses_file   = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-validation.jsonl'\n",
    "val_labels_file      = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-validation-labels.jsonl'\n",
    "test_responses_file  = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-test.jsonl'\n",
    "test_labels_file     = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-test-labels.jsonl'\n",
    "\n",
    "# Load datasets\n",
    "train_ids, train_texts, train_labels = load_dataset(train_responses_file, train_labels_file)\n",
    "val_ids, val_texts, val_labels = load_dataset(val_responses_file, val_labels_file)\n",
    "test_ids, test_texts, test_labels = load_dataset(test_responses_file, test_labels_file)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Experiment: Naïve Bayes Classifier (NBC) with TF-IDF\n",
    "# Classifier: Multinomial Naïve Bayes\n",
    "# Feature Extraction: TF-IDF\n",
    "# Goal: Evaluate performance of NBC on the TF-IDF representation of the responses.\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# Build the pipeline: TF-IDF vectorizer + MultinomialNB\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(stop_words='english', max_df=0.95),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Cross-Validation on Training Set\n",
    "# -------------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipeline, train_texts, train_labels, cv=cv, scoring='f1_macro')\n",
    "print(\"Cross-validation F1 Macro Scores on Training Set:\", cv_scores)\n",
    "print(\"Mean Cross-Validation F1 Macro Score:\", np.mean(cv_scores))\n",
    "\n",
    "# -------------------------\n",
    "# Train the Model on the Full Training Set\n",
    "# -------------------------\n",
    "pipeline.fit(train_texts, train_labels)\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Training Set\n",
    "# -------------------------\n",
    "train_preds = pipeline.predict(train_texts)\n",
    "print(\"\\nTraining Set Evaluation:\")\n",
    "print(classification_report(train_labels, train_preds))\n",
    "print(\"Confusion Matrix (Training):\")\n",
    "print(confusion_matrix(train_labels, train_preds))\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Validation Set\n",
    "# -------------------------\n",
    "val_preds = pipeline.predict(val_texts)\n",
    "print(\"\\nValidation Set Evaluation:\")\n",
    "print(classification_report(val_labels, val_preds))\n",
    "print(\"Confusion Matrix (Validation):\")\n",
    "print(confusion_matrix(val_labels, val_preds))\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Test Set\n",
    "# -------------------------\n",
    "test_preds = pipeline.predict(test_texts)\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(classification_report(test_labels, test_preds))\n",
    "print(\"Confusion Matrix (Test):\")\n",
    "print(confusion_matrix(test_labels, test_preds))\n",
    "\n",
    "# -------------------------\n",
    "# Submission File Generation\n",
    "# -------------------------\n",
    "submission_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/nbc_baseline.jsonl'\n",
    "with open(submission_file, 'w', encoding='utf-8') as f_out:\n",
    "    for instance_id, pred in zip(test_ids, test_preds):\n",
    "        result = {\n",
    "            \"id\": instance_id,\n",
    "            \"label\": int(pred),  # ensuring it's an integer (0 or 1)\n",
    "            \"tag\": \"myGroupMyMethod\"\n",
    "        }\n",
    "        f_out.write(json.dumps(result) + \"\\n\")\n",
    "        \n",
    "print(f\"\\nSubmission file saved to: {submission_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uses GridSearchCV to tune the smoothing parameter (alpha) for the Multinomial Naïve Bayes classifier in a pipeline with TF-IDF feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.1\n",
      "Best CV F1 Macro Score: 0.5423436706182134\n",
      "\n",
      "Training Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      7541\n",
      "           1       0.87      0.61      0.72      3946\n",
      "\n",
      "    accuracy                           0.84     11487\n",
      "   macro avg       0.85      0.78      0.80     11487\n",
      "weighted avg       0.84      0.84      0.83     11487\n",
      "\n",
      "Confusion Matrix (Training):\n",
      "[[7194  347]\n",
      " [1543 2403]]\n",
      "\n",
      "Validation Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84      2075\n",
      "           1       0.87      0.40      0.55      1182\n",
      "\n",
      "    accuracy                           0.76      3257\n",
      "   macro avg       0.80      0.68      0.69      3257\n",
      "weighted avg       0.79      0.76      0.73      3257\n",
      "\n",
      "Confusion Matrix (Validation):\n",
      "[[2005   70]\n",
      " [ 712  470]]\n",
      "\n",
      "Test Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.97      0.84      1687\n",
      "           1       0.88      0.34      0.49       913\n",
      "\n",
      "    accuracy                           0.75      2600\n",
      "   macro avg       0.80      0.66      0.66      2600\n",
      "weighted avg       0.78      0.75      0.71      2600\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[1643   44]\n",
      " [ 605  308]]\n",
      "\n",
      "Submission file saved to: /Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/nb_gridsearch.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def load_dataset(responses_file, labels_file):\n",
    "    \"\"\"\n",
    "    Load dataset by reading responses and labels from JSONL files and merging them.\n",
    "    \"\"\"\n",
    "    # Load responses into a dictionary mapping id -> response text\n",
    "    responses = {}\n",
    "    with open(responses_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            # Optionally combine 'query' and 'response' if needed.\n",
    "            responses[data[\"id\"]] = data[\"response\"]\n",
    "    \n",
    "    # Load labels and merge with responses\n",
    "    ids, texts, labels = [], [], []\n",
    "    with open(labels_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            instance_id = data[\"id\"]\n",
    "            if instance_id in responses:\n",
    "                ids.append(instance_id)\n",
    "                texts.append(responses[instance_id])\n",
    "                labels.append(data[\"label\"])\n",
    "    \n",
    "    return ids, texts, labels\n",
    "\n",
    "# File paths (update these paths as needed)\n",
    "train_responses_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-train.jsonl'\n",
    "train_labels_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-train-labels.jsonl'\n",
    "val_responses_file   = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-validation.jsonl'\n",
    "val_labels_file      = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-validation-labels.jsonl'\n",
    "test_responses_file  = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-test.jsonl'\n",
    "test_labels_file     = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-test-labels.jsonl'\n",
    "\n",
    "# Load datasets\n",
    "train_ids, train_texts, train_labels = load_dataset(train_responses_file, train_labels_file)\n",
    "val_ids, val_texts, val_labels = load_dataset(val_responses_file, val_labels_file)\n",
    "test_ids, test_texts, test_labels = load_dataset(test_responses_file, test_labels_file)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Experiment: GridSearch on Multinomial Naïve Bayes with TF-IDF\n",
    "# Classifier: Multinomial Naïve Bayes\n",
    "# Feature Extraction: TF-IDF\n",
    "# Goal: Use GridSearchCV to experiment with different alpha values \n",
    "#       (e.g., 0.001, 0.01, 0.1, 1.0, 10) to find the optimal smoothing parameter.\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# Build the pipeline: TF-IDF vectorizer + MultinomialNB\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(stop_words='english', max_df=0.95),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "# Define the parameter grid for alpha\n",
    "param_grid = {\n",
    "    'multinomialnb__alpha': [0.001, 0.01, 0.1, 1.0, 10]\n",
    "}\n",
    "\n",
    "# Setup grid search with 5-fold stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
    "grid_search.fit(train_texts, train_labels)\n",
    "\n",
    "# Print best alpha and corresponding score\n",
    "print(\"Best alpha:\", grid_search.best_params_['multinomialnb__alpha'])\n",
    "print(\"Best CV F1 Macro Score:\", grid_search.best_score_)\n",
    "\n",
    "# Use the best model from grid search for evaluation\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Training Set\n",
    "# -------------------------\n",
    "train_preds = best_model.predict(train_texts)\n",
    "print(\"\\nTraining Set Evaluation:\")\n",
    "print(classification_report(train_labels, train_preds))\n",
    "print(\"Confusion Matrix (Training):\")\n",
    "print(confusion_matrix(train_labels, train_preds))\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Validation Set\n",
    "# -------------------------\n",
    "val_preds = best_model.predict(val_texts)\n",
    "print(\"\\nValidation Set Evaluation:\")\n",
    "print(classification_report(val_labels, val_preds))\n",
    "print(\"Confusion Matrix (Validation):\")\n",
    "print(confusion_matrix(val_labels, val_preds))\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Test Set\n",
    "# -------------------------\n",
    "test_preds = best_model.predict(test_texts)\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(classification_report(test_labels, test_preds))\n",
    "print(\"Confusion Matrix (Test):\")\n",
    "print(confusion_matrix(test_labels, test_preds))\n",
    "\n",
    "# -------------------------\n",
    "# Submission File Generation\n",
    "# -------------------------\n",
    "submission_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/nb_gridsearch.jsonl'\n",
    "with open(submission_file, 'w', encoding='utf-8') as f_out:\n",
    "    for instance_id, pred in zip(test_ids, test_preds):\n",
    "        result = {\n",
    "            \"id\": instance_id,\n",
    "            \"label\": int(pred),  # ensuring it's an integer (0 or 1)\n",
    "            \"tag\": \"myGroupMyMethod\"\n",
    "        }\n",
    "        f_out.write(json.dumps(result) + \"\\n\")\n",
    "        \n",
    "print(f\"\\nSubmission file saved to: {submission_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1 Macro Scores on Training Set: [0.48632078 0.50805709 0.49582183 0.50031821 0.49875823]\n",
      "Mean Cross-Validation F1 Macro Score: 0.4978552285260798\n",
      "\n",
      "Training Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84      7541\n",
      "           1       0.86      0.34      0.49      3946\n",
      "\n",
      "    accuracy                           0.75     11487\n",
      "   macro avg       0.80      0.65      0.66     11487\n",
      "weighted avg       0.78      0.75      0.72     11487\n",
      "\n",
      "Confusion Matrix (Training):\n",
      "[[7314  227]\n",
      " [2604 1342]]\n",
      "\n",
      "Validation Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.82      2075\n",
      "           1       0.85      0.28      0.42      1182\n",
      "\n",
      "    accuracy                           0.72      3257\n",
      "   macro avg       0.78      0.63      0.62      3257\n",
      "weighted avg       0.76      0.72      0.67      3257\n",
      "\n",
      "Confusion Matrix (Validation):\n",
      "[[2015   60]\n",
      " [ 850  332]]\n",
      "\n",
      "Test Set Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81      1687\n",
      "           1       0.86      0.18      0.29       913\n",
      "\n",
      "    accuracy                           0.70      2600\n",
      "   macro avg       0.77      0.58      0.55      2600\n",
      "weighted avg       0.75      0.70      0.63      2600\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[1660   27]\n",
      " [ 751  162]]\n",
      "\n",
      "Submission file saved to: /Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/comp_nb_baseline.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "def load_dataset(responses_file, labels_file):\n",
    "    \"\"\"\n",
    "    Load dataset by reading responses and labels from JSONL files and merging them.\n",
    "    \"\"\"\n",
    "    # Load responses into a dictionary mapping id -> response text\n",
    "    responses = {}\n",
    "    with open(responses_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            # Optionally combine 'query' and 'response' if needed.\n",
    "            responses[data[\"id\"]] = data[\"response\"]\n",
    "    \n",
    "    # Load labels and merge with responses\n",
    "    ids, texts, labels = [], [], []\n",
    "    with open(labels_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            instance_id = data[\"id\"]\n",
    "            if instance_id in responses:\n",
    "                ids.append(instance_id)\n",
    "                texts.append(responses[instance_id])\n",
    "                labels.append(data[\"label\"])\n",
    "    \n",
    "    return ids, texts, labels\n",
    "\n",
    "# File paths (update these paths as needed)\n",
    "train_responses_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-train.jsonl'\n",
    "train_labels_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-train-labels.jsonl'\n",
    "val_responses_file   = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-validation.jsonl'\n",
    "val_labels_file      = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-validation-labels.jsonl'\n",
    "test_responses_file  = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-test.jsonl'\n",
    "test_labels_file     = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/responses-test-labels.jsonl'\n",
    "\n",
    "# Load datasets\n",
    "train_ids, train_texts, train_labels = load_dataset(train_responses_file, train_labels_file)\n",
    "val_ids, val_texts, val_labels = load_dataset(val_responses_file, val_labels_file)\n",
    "test_ids, test_texts, test_labels = load_dataset(test_responses_file, test_labels_file)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Experiment: Complement Naïve Bayes (ComplementNB) with TF-IDF\n",
    "# Classifier: Complement Naïve Bayes\n",
    "# Feature Extraction: TF-IDF\n",
    "# Goal: Evaluate performance of ComplementNB, which is often more robust for imbalanced data.\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# Build the pipeline: TF-IDF vectorizer + ComplementNB\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(stop_words='english', max_df=0.95),\n",
    "    ComplementNB(alpha=1.0)\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Cross-Validation on Training Set\n",
    "# -------------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipeline, train_texts, train_labels, cv=cv, scoring='f1_macro')\n",
    "print(\"Cross-validation F1 Macro Scores on Training Set:\", cv_scores)\n",
    "print(\"Mean Cross-Validation F1 Macro Score:\", np.mean(cv_scores))\n",
    "\n",
    "# -------------------------\n",
    "# Train the Model on the Full Training Set\n",
    "# -------------------------\n",
    "pipeline.fit(train_texts, train_labels)\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Training Set\n",
    "# -------------------------\n",
    "train_preds = pipeline.predict(train_texts)\n",
    "print(\"\\nTraining Set Evaluation:\")\n",
    "print(classification_report(train_labels, train_preds))\n",
    "print(\"Confusion Matrix (Training):\")\n",
    "print(confusion_matrix(train_labels, train_preds))\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Validation Set\n",
    "# -------------------------\n",
    "val_preds = pipeline.predict(val_texts)\n",
    "print(\"\\nValidation Set Evaluation:\")\n",
    "print(classification_report(val_labels, val_preds))\n",
    "print(\"Confusion Matrix (Validation):\")\n",
    "print(confusion_matrix(val_labels, val_preds))\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation on Test Set\n",
    "# -------------------------\n",
    "test_preds = pipeline.predict(test_texts)\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(classification_report(test_labels, test_preds))\n",
    "print(\"Confusion Matrix (Test):\")\n",
    "print(confusion_matrix(test_labels, test_preds))\n",
    "\n",
    "# -------------------------\n",
    "# Submission File Generation\n",
    "# -------------------------\n",
    "submission_file = '/Users/tarekbouhairi/Desktop/Universitat Passau/Advertismenet in RAG/Ad-Detection/comp_nb_baseline.jsonl'\n",
    "with open(submission_file, 'w', encoding='utf-8') as f_out:\n",
    "    for instance_id, pred in zip(test_ids, test_preds):\n",
    "        result = {\n",
    "            \"id\": instance_id,\n",
    "            \"label\": int(pred),  # ensuring it's an integer (0 or 1)\n",
    "            \"tag\": \"myGroupMyMethod\"\n",
    "        }\n",
    "        f_out.write(json.dumps(result) + \"\\n\")\n",
    "        \n",
    "print(f\"\\nSubmission file saved to: {submission_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
